# coding: utf-8

"""
    Datamonkey API

    Datamonkey is a free public server for comparative analysis of sequence alignments using state-of-the-art statistical models. <br> This is the OpenAPI definition for the Datamonkey API. 

    The version of the OpenAPI document: 1.2.0
    Contact: spond@temple.edu
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from openapi_client.models.analysis_info import AnalysisInfo
from openapi_client.models.input_info import InputInfo
from openapi_client.models.partitions_info_value import PartitionsInfoValue
from openapi_client.models.slatkin_result_result_all_of_events_value import SlatkinResultResultAllOfEventsValue
from openapi_client.models.slatkin_result_result_all_of_node_p_value import SlatkinResultResultAllOfNodePValue
from openapi_client.models.slatkin_result_result_all_of_p_value import SlatkinResultResultAllOfPValue
from openapi_client.models.slatkin_result_result_all_of_simulations import SlatkinResultResultAllOfSimulations
from openapi_client.models.timers_info_value import TimersInfoValue
from typing import Optional, Set
from typing_extensions import Self

class SlatkinResultResult(BaseModel):
    """
    SlatkinResultResult
    """ # noqa: E501
    analysis: Optional[AnalysisInfo] = None
    input: Optional[InputInfo] = None
    tested: Optional[Dict[str, Dict[str, StrictStr]]] = None
    timers: Optional[Dict[str, TimersInfoValue]] = None
    runtime: Optional[Annotated[str, Field(strict=True)]] = None
    data_partitions: Optional[Dict[str, PartitionsInfoValue]] = Field(default=None, alias="data partitions")
    compartments: Optional[StrictInt] = Field(default=None, description="Number of compartments in the analysis")
    events: Optional[Dict[str, SlatkinResultResultAllOfEventsValue]] = Field(default=None, description="Migration events between compartments")
    leaf_count: Optional[StrictInt] = Field(default=None, description="Number of leaves in the tree", alias="leaf-count")
    migrations: Optional[StrictInt] = Field(default=None, description="Number of migration events")
    p_value: Optional[SlatkinResultResultAllOfPValue] = Field(default=None, alias="p-value")
    partition_counts: Optional[Dict[str, StrictInt]] = Field(default=None, description="Number of sequences in each partition/compartment", alias="partition-counts")
    partitions: Optional[Dict[str, Dict[str, StrictStr]]] = Field(default=None, description="Sequences in each partition/compartment")
    replicates: Optional[StrictInt] = Field(default=None, description="Number of bootstrap replicates used")
    node_migrations: Optional[Dict[str, StrictInt]] = Field(default=None, description="Number of migrations at each node", alias="node-migrations")
    structured_cutoff: Optional[StrictInt] = Field(default=None, description="Cutoff value for structured test", alias="structured-cutoff")
    node_p_value: Optional[SlatkinResultResultAllOfNodePValue] = Field(default=None, alias="node-p-value")
    simulations: Optional[SlatkinResultResultAllOfSimulations] = None
    __properties: ClassVar[List[str]] = ["analysis", "input", "tested", "timers", "runtime", "data partitions", "compartments", "events", "leaf-count", "migrations", "p-value", "partition-counts", "partitions", "replicates", "node-migrations", "structured-cutoff", "node-p-value", "simulations"]

    @field_validator('tested')
    def tested_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        for i in value.values():
            if i not in set(['tested', 'background']):
                raise ValueError("dict values must be one of enum values ('tested', 'background')")
        return value

    @field_validator('runtime')
    def runtime_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r"^[0-9]+\.[0-9]+\.[0-9]+$", value):
            raise ValueError(r"must validate the regular expression /^[0-9]+\.[0-9]+\.[0-9]+$/")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of SlatkinResultResult from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of analysis
        if self.analysis:
            _dict['analysis'] = self.analysis.to_dict()
        # override the default output from pydantic by calling `to_dict()` of input
        if self.input:
            _dict['input'] = self.input.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each value in timers (dict)
        _field_dict = {}
        if self.timers:
            for _key_timers in self.timers:
                if self.timers[_key_timers]:
                    _field_dict[_key_timers] = self.timers[_key_timers].to_dict()
            _dict['timers'] = _field_dict
        # override the default output from pydantic by calling `to_dict()` of each value in data_partitions (dict)
        _field_dict = {}
        if self.data_partitions:
            for _key_data_partitions in self.data_partitions:
                if self.data_partitions[_key_data_partitions]:
                    _field_dict[_key_data_partitions] = self.data_partitions[_key_data_partitions].to_dict()
            _dict['data partitions'] = _field_dict
        # override the default output from pydantic by calling `to_dict()` of each value in events (dict)
        _field_dict = {}
        if self.events:
            for _key_events in self.events:
                if self.events[_key_events]:
                    _field_dict[_key_events] = self.events[_key_events].to_dict()
            _dict['events'] = _field_dict
        # override the default output from pydantic by calling `to_dict()` of p_value
        if self.p_value:
            _dict['p-value'] = self.p_value.to_dict()
        # override the default output from pydantic by calling `to_dict()` of node_p_value
        if self.node_p_value:
            _dict['node-p-value'] = self.node_p_value.to_dict()
        # override the default output from pydantic by calling `to_dict()` of simulations
        if self.simulations:
            _dict['simulations'] = self.simulations.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of SlatkinResultResult from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "analysis": AnalysisInfo.from_dict(obj["analysis"]) if obj.get("analysis") is not None else None,
            "input": InputInfo.from_dict(obj["input"]) if obj.get("input") is not None else None,
            "tested": obj.get("tested"),
            "timers": dict(
                (_k, TimersInfoValue.from_dict(_v))
                for _k, _v in obj["timers"].items()
            )
            if obj.get("timers") is not None
            else None,
            "runtime": obj.get("runtime"),
            "data partitions": dict(
                (_k, PartitionsInfoValue.from_dict(_v))
                for _k, _v in obj["data partitions"].items()
            )
            if obj.get("data partitions") is not None
            else None,
            "compartments": obj.get("compartments"),
            "events": dict(
                (_k, SlatkinResultResultAllOfEventsValue.from_dict(_v))
                for _k, _v in obj["events"].items()
            )
            if obj.get("events") is not None
            else None,
            "leaf-count": obj.get("leaf-count"),
            "migrations": obj.get("migrations"),
            "p-value": SlatkinResultResultAllOfPValue.from_dict(obj["p-value"]) if obj.get("p-value") is not None else None,
            "partition-counts": obj.get("partition-counts"),
            "partitions": obj.get("partitions"),
            "replicates": obj.get("replicates"),
            "node-migrations": obj.get("node-migrations"),
            "structured-cutoff": obj.get("structured-cutoff"),
            "node-p-value": SlatkinResultResultAllOfNodePValue.from_dict(obj["node-p-value"]) if obj.get("node-p-value") is not None else None,
            "simulations": SlatkinResultResultAllOfSimulations.from_dict(obj["simulations"]) if obj.get("simulations") is not None else None
        })
        return _obj


